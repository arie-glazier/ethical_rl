{
  "cartpole" : {
    "environment_name" : "CartPole-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.base"],
      "classes" : ["BaseWrapper"]
    },
    "model_module" : "ethical_rl.models.sequential.perceptron"
  },
  "double_dqn" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["gym_minigrid.wrappers"], 
      "classes" : ["FlatObsWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.perceptron"
  },
  "double_dueling_dqn" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["gym_minigrid.wrappers"], 
      "classes" : ["FlatObsWrapper"],
      "note" : "This flattens representations"
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn"
  },
  "imgobs" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["gym_minigrid.wrappers","gym_minigrid.wrappers"], 
      "classes" : ["RGBImgPartialObsWrapper", "ImgObsWrapper"]
    },
    "model_module" : "ethical_rl.models.sequential.cnn"
  },
  "sym_wrapper_rainbow_params" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module" : "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "learning_rate" : 0.000125,
    "batch_size" : 32,
    "discount_factor" : 0.99
  },
  "q_learning" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.q_learning",
    "learning_rate" : 0.05,
    "discount_factor" : 0.99,
    "number_of_episodes" : 50000
  },
  "double_simple_prioritized" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.perceptron",
    "replay_buffer_module" : "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "learning_rate" : 0.000125,
    "batch_size" : 32,
    "discount_factor" : 0.99
  },
  "double_simple_simple" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.perceptron",
    "replay_buffer_module" : "ethical_rl.algorithms.dqn.replay_buffer.simple",
    "learning_rate" : 0.000125,
    "batch_size" : 32,
    "discount_factor" : 0.99
  },
  "dqn_simple_simple" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.dqn",
    "model_module" : "ethical_rl.models.sequential.perceptron",
    "replay_buffer_module" : "ethical_rl.algorithms.dqn.replay_buffer.simple",
    "learning_rate" : 0.000125,
    "batch_size" : 32,
    "discount_factor" : 0.99
  },
  "double_dueling_simple" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module" : "ethical_rl.algorithms.dqn.replay_buffer.simple",
    "learning_rate" : 0.000125,
    "batch_size" : 32,
    "discount_factor" : 0.99
  },
  "dqn_clip_norm" : {
    "environment_name" : "MiniGrid-arie-test-v0",
    "environment_wrapper" : {
      "modules" : ["gym_minigrid.wrappers"],
      "classes" : ["FlatObsWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.dqn",
    "model_module" : "ethical_rl.models.sequential.perceptron",
    "clip_norm": 5.0
  },
  "double_dueling_prioritized" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 2000000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.70,
    "termination_reward" : 1,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10
  },
  "double_dueling_prioritized_random_start" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 2000000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.70,
    "termination_reward" : 1,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": true
  },
  "double" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 2000000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.70,
    "termination_reward" : 1,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10
  },
  "dqn" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.dqn",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 2000000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.70,
    "termination_reward" : 1,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10
  },
  "dueling" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 2000000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.70,
    "termination_reward" : 1,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10
  },
  "double_dueling" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 2000000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.70,
    "termination_reward" : 1,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10
  },
  "double_dueling_prioritized_constraint_aware" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.negative_step_constraint_aware",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 2000000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.70,
    "termination_reward" : 1,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10
  },
  "double_dueling_prioritized_large_aware" : {
    "environment_name" : "MiniGrid-Ethical10x10-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.negative_step_constraint_aware",
    "learning_rate" : 0.01,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 2000000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.95,
    "termination_reward" : 40,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 400,
    "number_of_episodes": 10000,
    "max_steps_per_episode" : 35,
    "random_start_position": true,
    "constraint_violation_penalty" : -5
  },
  "double_dueling_prioritized_large_unaware" : {
    "environment_name" : "MiniGrid-Ethical10x10-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 2000000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.70,
    "termination_reward" : 1,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 100,
    "number_of_episodes": 10000,
    "max_steps_per_episode" : 20,
    "random_start_position": false
  },
  "double_dueling_prioritized_pref_human" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.90,
    "termination_reward" : 5,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": true
  },
  "lunar_lander_dqn": {
    "environment_name": "LunarLander-v2",
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "include_environment_config": false,
    "environment_wrapper": {},
    "learning_rate" : 0.001,
    "batch_size" : 64,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 1000000,
    "epsilon_end" : 0.001,
    "epsilon_anneal_percent" : 0.1,
    "discount_factor" : 0.99,
    "target_sync_frequency" : 2,
    "number_of_episodes": 1000,
    "buffer_wait_steps" : 2,
    "maximum_step_size" : 300000
  },
  "double_dueling_prioritized_human_labels_0" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "reward_model_path": "./saved_models/human_0.h5",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.30,
    "termination_reward" : 0,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": false
  },
  "double_dueling_prioritized_human_labels_10" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "reward_model_path": "./saved_models/human_10.h5",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.30,
    "termination_reward" : 0,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": false,
    "results_destination": "./data/ablation"
  },
  "double_dueling_prioritized_human_labels_100" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "reward_model_path": "./saved_models/human_100.h5",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.30,
    "termination_reward" : 0,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": false,
    "results_destination": "./data/ablation"
  },
  "double_dueling_prioritized_synthetic_labels_0" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "reward_model_path": "./saved_models/synthetic_0.h5",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.30,
    "termination_reward" : 0,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": false,
    "results_destination": "./data/ablation"
  },
  "double_dueling_prioritized_synthetic_labels_10" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "reward_model_path": "./saved_models/synthetic_10.h5",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.30,
    "termination_reward" : 0,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": false,
    "results_destination": "./data/ablation"
  },
  "double_dueling_prioritized_synthetic_labels_100" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "reward_model_path": "./saved_models/synthetic_100.h5",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.30,
    "termination_reward" : 0,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": false,
    "results_destination": "./data/ablation"
  },
  "double_dueling_prioritized_synthetic_labels_1000" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "reward_model_path": "./saved_models/synthetic_1000.h5",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.30,
    "termination_reward" : 5,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": false,
    "results_destination": "./data/ablation"
  },
  "double_dueling_prioritized_synthetic_labels_1455" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "reward_model_path": "./saved_models/synthetic_1455.h5",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.30,
    "termination_reward" : 5,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": false,
    "results_destination": "./data/ablation"
  },
  "double_dueling_prioritized_synthetic_labels_test" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapper"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.neural_network",
    "reward_model_path": "./saved_models/reward_model_syn.h5",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.30,
    "termination_reward" : 5,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 10,
    "random_start_position": false,
    "results_destination": "./data/ablation"
  },
  "double_dueling_prioritized_object" : {
    "environment_name" : "MiniGrid-Ethical5x5Object-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations"], 
      "classes" : ["SymbolicObservationsOneHotWrapperObject"]
    },
    "algorithm_module" : "ethical_rl.algorithms.dqn.double_dqn",
    "model_module" : "ethical_rl.models.sequential.dueling_dqn",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.prioritized",
    "reward_module" : "ethical_rl.environments.rewards.object_constraint_aware",
    "learning_rate" : 0.05,
    "batch_size" : 128,
    "fully_connected_model_size" : [100, 100],
    "max_replay_buffer_length" : 200000,
    "epsilon_end" : 0.0001,
    "epsilon_anneal_percent" : 0.80,
    "termination_reward" : 5,
    "discount_factor" : 1.0,
    "target_sync_frequency" : 100,
    "number_of_episodes": 1000,
    "max_steps_per_episode" : 25,
    "random_start_position": true,
    "constraint_violation_penalty": -10
  },
  "anwar" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations","tf_agents.environments.gym_wrapper","tf_agents.environments.tf_py_environment"], 
      "classes" : ["SymbolicObservationsOneHotWrapper", "GymWrapper","TFPyEnvironment"]
    },
    "algorithm_module" : "ethical_rl.algorithms.ppo",
    "model_module" : "ethical_rl.models.value_network",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.tf_uniform",
    "reward_module" : "ethical_rl.environments.rewards.negative_step_constraint_aware",
    "policy_module": "ethical_rl.policies.actor_network",
    "optimizer" : "Adam",
    "learning_rate" : 1.23e-3,
    "batch_size" : 128,
    "fully_connected_model_size" : [64, 64],
    "max_replay_buffer_length" : 20000,
    "termination_reward" : 5,
    "step_reward" : -1,
    "constraint_violation_penalty": -10,
    "discount_factor" : 0.99,
    "number_of_episodes": 100,
    "clip_ratio": 0.13,
    "target_kl": 0.01,
    "td_lambda_value": 1.0,
    "include_environment_config": true,
    "max_steps_per_episode" : 10,
    "evaluate_steps": 25,
    "render_steps": 6,
    "rollout_length": 200,
    "num_epochs": 3
  },
  "icrl" : {
    "environment_name" : "MiniGrid-Ethical5x5-v0",
    "environment_wrapper" : {
      "modules" : ["ethical_rl.wrappers.symbolic_observations","tf_agents.environments.gym_wrapper","tf_agents.environments.tf_py_environment"], 
      "classes" : ["SymbolicObservationsOneHotWrapper", "GymWrapper","TFPyEnvironment"]
    },
    "algorithm_module" : "ethical_rl.algorithms.ppo.icrl",
    "model_module" : "ethical_rl.models.value_network",
    "replay_buffer_module": "ethical_rl.algorithms.dqn.replay_buffer.tf_uniform",
    "reward_module" : "ethical_rl.environments.rewards.negative_step",
    "policy_module": "ethical_rl.policies.actor_network",
    "optimizer" : "Adam",
    "learning_rate" : 1.23e-3,
    "batch_size" : 30,
    "fully_connected_model_size" : [64, 64],
    "max_replay_buffer_length" : 20000,
    "termination_reward" : 1,
    "step_reward" : -1,
    "constraint_violation_penalty": -10,
    "discount_factor" : 0.99,
    "number_of_episodes": 100,
    "clip_ratio": 0.13,
    "target_kl": 0.01,
    "td_lambda_value": 1.0,
    "include_environment_config": true,
    "max_steps_per_episode" : 10,
    "evaluate_steps": 100,
    "xrender_steps": 6,
    "rollout_length": 30,
    "num_epochs": 3,
    "alpha": 1.0,
    "initial_lambda_value": 1.0,
    "lambda_learning_rate": 1.0,
    "classifier_training_steps": 1,
    "policy_training_steps": 20
  }
}